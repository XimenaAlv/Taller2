{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1-cp38-cp38-manylinux1_x86_64.whl (371 kB)\n",
      "\u001b[K     |████████████████████████████████| 371 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /home/john/anaconda3/lib/python3.8/site-packages (from wordcloud) (1.20.1)\n",
      "Requirement already satisfied: matplotlib in /home/john/anaconda3/lib/python3.8/site-packages (from wordcloud) (3.3.4)\n",
      "Requirement already satisfied: pillow in /home/john/anaconda3/lib/python3.8/site-packages (from wordcloud) (8.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/john/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/john/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/john/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/john/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: six in /home/john/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /home/john/anaconda3/lib/python3.8/site-packages (3.12.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/john/.local/lib/python3.8/site-packages (3.6.2)\n",
      "Requirement already satisfied: click in /home/john/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/john/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: joblib in /home/john/anaconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex in /home/john/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to database and getting texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a connection to MongoDB\n",
    "client = MongoClient(\"localhost\", 27017)\n",
    "db = client[\"news\"]\n",
    "collection = db[\"elespectador\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for news in list(collection.find({}, {\"title\": 1, \"summary\": 1, \"full_text\": 1, \"_id\": 0})):\n",
    "    text.append(news[\"title\"])\n",
    "    text.append(news[\"summary\"])\n",
    "    text.append(news[\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jennifer Arias influyó en el voto de un representante en la Ley de Garantías El representante Anatolio Hernández, de la U, preguntó en plena transmisión cómo votar el artículo 125 del Presupuesto de 2022, que modifica la Ley de Garantías. Arias y otra representante le dijeron que votara afirmativamente. Las redes no perdonan ni olvidan y, aunque ya pasaron tres días desde la aprobación del Presupuesto General de 2022, se está reviviendo un momento de la discusión del proyecto en la Cámara de Representantes. Lea más contexto sobre la discusión alrededor de la Ley de Garantías.  El fragmento del video que circula en Twitter ilustra la votación del artículo que modifica la Ley de Garantías, el tema más polémico del presupuesto, y la postura del representante Anatolio Hernández, del Partido de la U, quien preguntó cómo votar y una colega y la presidenta de la corporación, Jennifer Arias, del Centro Democrático, lo llevan a que lo haga afirmativamente. Anatolio Hernández: ¿Cómo están votando? ¿Cómo voto? Secretario de la Cámara -haciendo llamado a lista-: Anatolio Hernández Anatolio Hernández: ¿Cómo voto? Jennifer Arias: Anatolio se está escuchando Voz de una mujer no reconocida: Anatolio vote sí Jennifer Arias: Anatolio vote sí Anatolio Hernández -dando la respuesta-: Voto sí Secretario de la Cámara -certificando el voto-: me repite su voto Anatolio Hernández: Anatolio vota sí Voz de hombre no reconocida: Anatolio vote no Anatolio Hernández en tono confundido: ¿Cómo? Voz de hombre no reconocida: ¿Anatolio Hernández cómo vota? Sí Voz de hombre no reconocida: Vote sí Voz de hombre no reconocida: Déjelo votar tranquilo Aunque el voto de Hernández no iba a incidir en el resultado 98 sobre 39, que estaban en contra de modificar la Ley de Garantías, la ciudadanía pone en tela de juicio la independencia del representante de la U, así como su atención a la discusión de un artículo trascendental para las elecciones de 2022, pues la pregunta sobre “¿cómo voto?” da a entender de un corporado que no está siguiendo el debate y debe cumplir con la votación. Le puede interesar: El condenado Pulgar buscaría (nuevamente) tener curul a través de su esposa.  Es más, sus colegas de la Cámara están criticando el comportamiento de Hernández. “Un nuevo episodio de cómo la Cámara se convierte en una notaría. Duele nuestra democracia”, escribió en Twitter José Daniel López, de Cambio Radical, haciendo alusión al video que circula en redes. López denunció que, en apenas 40 minutos, a la media noche del pasado miércoles y con múltiples apagadas de micrófonos a la oposición se aprobó el artículo 125 que modifica la Ley de Garantías y permite la contratación y convenios interadministrativos en pleno período electoral. Esta modificación tendría efecto, justamente, en los comicios de 2022. Según expertos y congresistas de la oposición, esto permite que las maquinarias clientelares que hacen presencia dentro de las administraciones locales, departamentales y nacionales muevan sus influencias para tomar ventaja en las elecciones. Situación que deja en alerta a los movimientos alternativos. Para muchos, el proyecto de Presupuesto 2022, que es una ley orgánica, debe pasar a revisión por parte de la Corte Constitucional ya que incluye el artículo de Ley de Garantías, que es una ley estatutaria y maneja unos trámites y mayorías diferentes a la orgánica. Es decir, si bien la ley de Presupuesto entraría en vigencia una vez sea sancionada por el presidente Iván Duque, el artículo que hace referencia a la Ley de Garantías debe pasar por revisión constitucional. Más: Corte Constitucional, último intento para evitar cambios a la Ley de Garantías.  “Antes de entrar en vigencia una ley como la ley de garantías por sus modificaciones tiene que ir a una revisión previa de la Corte Constitucional, y si no va a esa revisión previa, la Corte puede asumir de oficio de estudio de esa ley estatutaria. El presidente del Senado y la República, a quienes les va a llegar la ley orgánica del presupuesto con el mico incorporado, faltarían a sus deberes y se pueden ver incursos en una falta disciplinaria y ser investigados si no actúan conforme a la ley estatutaria, es decir, tienen que mandar el articulito a la Corte dentro de los seis días siguientes al momento que les llegue el proyecto para su firma, para que la Corte pueda analizarlo antes de entrar en vigencia. Sin antes de eso, la ley no puede ser aplicada por ningún funcionario en Colombia”, explicó Juan Fernando Cristo, exministro del Interior y ahora precandidato presidencial. Ya hay quienes hablan de demandas al artículo y al trámite del mismo, sin embargo, hasta que no sea sancionada y no entre en vigencia, no puede ser demandable. “Bases de datos del DANE no son confiables”: registrador nacional  El registrador nacional, Alexander Vega, dijo que en Colombia hay 55 millones de personas, más de las que reportó el DANE en el último censo. Juan Daniel Oviedo, director de la entidad, le pide dar el debate con las cifras que son. Durante la entrega de tres nuevas registradurías auxiliares en Soacha, el registrador nacional, Alexander Vega Rocha, lanzó duras críticas al Departamento Administrativo Nacional de Estadística (DANE) al afirmar que sus bases de datos no coinciden con las de la Registraduría. Según Vega, las cifras poblacionales que reporta la entidad sobre lugares como Soacha son menores a las reales, lo que puede afectar las transferencias que les hace el Gobierno a los municipios. Lea también: Así le fue a la economía colombiana en agosto de 2021 “Las bases de datos del DANE no son confiables frente al registro civil que tiene Colombia y la Registraduría. No es posible que a municipios como Soacha le pongan menos población de la que realmente tiene. Estoy dispuesto a dar el debate con el director del DANE”, aseguró el registrador. El funcionario también cuestionó las cifras del último censo nacional y dijo que el Gobierno no está aprovechando las bases de datos de la Registraduría. “Al país no hay que decirle mentiras. ¿Cómo explican que en el DANE somos 50 millones de colombianos y en la Registraduría, en el registro civil, somos 55 (millones)?”, dijo. El director del DANE, Juan Daniel Oviedo, respondió en Red+Noticias a dichas declaraciones, no sin antes aclarar que en Colombia somos un poco más de 51 millones de personas a junio de 2021 (esto, según las proyecciones a partir de los 48 millones identificados en el censo de 2018). “Nos sorprende que el registrador haga estas declaraciones en el sentido en que desde 2017 venimos trabajando articuladamente con la Registraduría”, dijo Oviedo. Para volver a leer: Colombia llegó a 50 millones de habitantes. ¿Ahora qué viene? Según el director del DANE, desde 2017 se hacen chequeos de las bases de datos cada tres meses y hay actas de comités técnicos. Además, ahora se desarrolla el Registro Estadístico Base de Población, que contiene más de 62 millones de registros clasificados y marcados. Oviedo explicó que en el registro civil nadie puede desaparecer, pues solo se hace una marca si la persona muere, migra o si se cancelan registros. “Le hemos enviado al señor registrador, después de haber cruzado con más de 34 registros administrativos, una lista de casi 3 millones de registros que están en la Registraduría y que seguramente están asociados con la estimación oficial que hace el sistema de Naciones Unidas de colombianos que residen en el exterior”, dijo. De los más de 60 millones de registros que tiene la Registraduría, hay unos 3,8 millones de fallecidos y 3,5 millones de marcas asociadas con cancelación. Es decir, a esos 60 millones de registros habría que restarle unas 11 millones de personas, dando las 49 millones de personas que certificó el DANE en 2018. También fue enfático en que así como la Registraduría tiene la competencia de identificar a los colombianos y organizar los procesos electorales, la ley establece que la autoridad estadística oficial en materia de certificaciones de población es el DANE. “Lo invitamos a que sigamos trabajando y nos envíe el estudio técnico que motivó esas declaraciones para que el debate se dé con cifras”, concluyó Oviedo. Gobierno, a rendir cuentas sobre sobre atención a mujeres víctimas del conflicto El Congreso citó a nueve entidades del Estado colombiano, entre ellas al Ejecutivo, para que expliquen lo que han hecho para prevenir y atender a esta población. Entre 2001 y 2009, cada hora hubo 6 mujeres que sufrieron violencia sexual en Colombia. El próximo miércoles 27 de octubre se tiene previsto que, ante el Congreso de la República y en desarrollo de una audiencia pública, el Gobierno de Iván Duque, así como otras entidades del Estado, rindan cuentas sobre las medidas que ha adoptado para prevenir y atender a las mujeres víctimas del conflicto armado, así como las garantías de no repetición. La audiencia será realizada en la Comisión Séptima del Senado, encargada, entre otros, de asuntos de la mujer y de la familia. A ella están citadas nueve instituciones que deberán dar cuenta sobre los instrumentos, marcos jurídicos y espacios de escucha que permitan prevenir y enfrentar la magnitud de la problemática. “La realidad de la violencia contra las mujeres es quizá uno de los conflictos sociales con menor visibilidad en el país, debido a múltiples factores de toda índole: la complejidad de las situaciones individuales de las mujeres, la falta de reconocimiento de esta problemática como un problema social, las barreras para el acceso a la justicia y la desigualdad estructural entre ambos sexos, entre otras”, explicaron los convocantes de la audiencia. Los citantes también recordaron cifras del Centro Nacional de Memoria Histórica que, en su informe “Guerra inscrita en el cuerpo”, documentó que hasta septiembre de 2017 había 15.076 personas víctimas de delitos contra la libertad y la integridad sexual en el marco del conflicto armado. De estas, el 91,6 % eran niñas, adolescentes y mujeres adultas. Por otro lado, la campaña “violaciones y otras violencias: saquen mi cuerpo de la guerra” encontró que entre 2001 y 2009, en promedio, cada hora hubo 6 mujeres que sufrieron violencia sexual en Colombia. Adicionalmente, una encuesta aplicada por organizaciones de mujeres, también entre 2000 y 2009, señaló que 12.809 mujeres fueron víctimas de violación relacionada al conflicto, otras 1.575 obligadas a ejercer la prostitución, 4.415 con embarazos forzados y 1.810 víctimas abortos forzados. “Con todo esto, la tesis de que los cuerpos de las mujeres han sido utilizados en este conflicto para lograr objetivos militares y como botín de guerra, pero también para ejercer control social y territorial sigue siendo vigente”, advirtieron, llamando la atención por dificultades como el subregistro, “pues las mujeres han optado por guardar su dolor y no contar lo sucedido por miedo a ser señaladas, estigmatizadas o incluso revictimizadas por las mismas instituciones encargadas de tratar los temas o de impartir justicia”. Los citantes son los senadores Aida Avella (UP), Alberto Castilla e Iván Cepeda (Polo Democrático), junto a organizaciones como Oxfam Colombia, Tejido Mujer ACIN, la Fundación Nydia Erika Bautista y Casa de la Mujer. Deberían rendir cuentas instituciones como el Sistema de Verdad, Justicia y Reparación, el Ministerio Público y los despachos presidenciales encargados de estos asuntos. También para Congreso: ya van 129 comités que buscan recolectar firmas La Registraduría precisó que no se exigirán más de 50.000 firmas válidas para la inscripción con miras a las elecciones de marzo próximo. El plazo para el registro de comités vence el 13 de noviembre del 2021. No solo es un fenómeno que se presente con miras a las elecciones para presidente de la República. Según cifras de la Registraduría Nacional reveladas este jueves, hasta ahora se han registrado 129 comités inscriptores al Congreso por grupos significativos de ciudadanos y movimientos sociales, buscando avalar sus candidaturas a través de firmas.  En contexto: ¿Campaña anticipada? Póngale la firma De acuerdo con la entidad, los comités inscritos no son solo para avalar candidaturas, sino para promover el voto en blanco con miras a las elecciones legislativas, que se celebrarán en marzo próximo. “Del total, 66 corresponden a comités inscriptores de candidaturas a la Cámara de Representantes (61 por circunscripción territorial y cinco por la circunscripción internacional), 41 a comités inscriptores de candidaturas al Senado, 8 a comités promotores del voto en blanco (cuatro por Cámara y cuatro por Senado) y 14 a comités que desistieron del registro (nueve a la Cámara y cinco al Senado”, explicó la Registraduría. En el caso de los comités para Congreso, deberán recoger un número mínimo de firmas válidas equivalente al 20 % del resultado de la división de la cantidad de ciudadanos aptos para votar en la respectiva circunscripción electoral, entre el número de curules por proveer. En todo caso, en ningún caso se exigirán más de 50.000 firmas válidas para la inscripción. Lea también: Firmas: ¿espejismo o avance democrático? “El término para el registro de los comités inscriptores de candidaturas y promotores del voto en blanco apoyados por grupos significativos de ciudadanos y movimientos sociales vence el 13 de noviembre del 2021, esto, de acuerdo con lo establecido en el calendario electoral para las elecciones del Congreso”, precisó. Con corte al pasado 17 de septiembre, según datos de la Registraduría conocidos por este diario, solo para Presidencia de la República se contaba con al menos 30 comités para recoger las firmas que servirán de sostén para el aspirante. Ello implica que, en solo cuatro meses, y a tres de que concluya la inscripción de más, ya se cuentan más de la mitad del total de grupos que se registraron para 2018. Los beneficios de conformar el pelotón de candidatos por firmas no son de poca monta. Aunque la norma indica que los aspirantes solo pueden iniciar la propaganda electoral tres meses antes de la elección -en el caso de los presidenciables el 28 de febrero-, quienes se le miden a recoger rubricas tienen patente de corso para salir a las calles y ganar visibilidad con la recolección de apoyos, pueden sumar recursos sin mayor vigilancia y hasta marginarse de partidos políticos tradicionales, sacando pecho como “independientes”. Una muestra de ello se vivió hace apenas dos años, en los últimos comicios en el país: las elecciones de alcaldes, gobernadores y autoridades locales. En 2019, los Grupos Significativos de Ciudadanos llegaron a los 1.164. Incluso, al revisar las elecciones legislativas de 2014, se evidencia que para Senado hubo 55 y para Cámara de Representantes 117.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower() # WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/john/nltk_data'\n    - '/home/john/anaconda3/nltk_data'\n    - '/home/john/anaconda3/share/nltk_data'\n    - '/home/john/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-88b932caa526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/john/nltk_data'\n    - '/home/john/anaconda3/nltk_data'\n    - '/home/john/anaconda3/share/nltk_data'\n    - '/home/john/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec_dist = FreqDist(words)\n",
    "\n",
    "print(frec_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec_dist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.bar([ w[0] for w in frec_dist.most_common(n) ], [ w[1] for w in frec_dist.most_common(n) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size = 50, max_words = 100, background_color = \"white\").generate(text)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords\n",
    "\n",
    "Stop words are basically a set of commonly used words in any language, not just English.\n",
    "\n",
    "The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"spanish\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_words = []\n",
    "for w in words:\n",
    "    if w not in stop_words:\n",
    "        filtered_words.append(w)\n",
    "\n",
    "print(\"All words:\", words)\n",
    "print(\"\\n\")\n",
    "print(\"Substracting stopwords:\", filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_font_size = 50, max_words = 100, background_color = \"white\").generate(\" \".join(filtered_words))\n",
    "\n",
    "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech\n",
    "\n",
    "https://nlp.stanford.edu/software/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar = \"./pos-tagger/stanford-postagger/stanford-postagger-4.2.0.jar\"\n",
    "model = \"./pos-tagger/stanford-postagger/models/spanish-ud.tagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_path = \"/usr/bin/java\"\n",
    "os.environ[\"JAVAHOME\"] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger = StanfordPOSTagger(model, jar, encoding = \"utf8\")\n",
    "pos_tagger.tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
